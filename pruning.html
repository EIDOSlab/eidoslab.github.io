<!DOCTYPE html>
<html>

  <head>


  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="Digital image processing, computer vision and virtual reality">
  <meta name="author" content="EIDOSlab">
  <link rel="canonical" href="/pruning">

  <title>Pruning | EIDOSlab</title>

  <!-- Bootstrap core CSS -->
  <link href="assets/css/bootstrap.min.css" rel="stylesheet">

  <!-- Custom fonts for this template -->
  <link href="assets/css/all.min.css" rel="stylesheet" type="text/css">
  <link href="https://fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet" type="text/css">
  <link href='https://fonts.googleapis.com/css?family=Kaushan+Script' rel='stylesheet' type='text/css'>
  <link href='https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
  <link href='https://fonts.googleapis.com/css?family=Roboto+Slab:400,100,300,700' rel='stylesheet' type='text/css'>

  <!-- Custom styles for this theme -->
  <!--<link href="assets/css/agency.min.css" rel="stylesheet">-->
  <link href="assets/css/agency.css" rel="stylesheet">

  <!-- Page container change top padding when nav shrinks -->
  
  <style>
    #pagecontainer {padding-top: 150px;}
	@media only screen and (max-width: 991px) {
	  #pagecontainer {padding-top: 100px;}
	}
  </style>
  

</head>


  <body id="page-top">

      <!-- Navigation -->
  <nav class="navbar navbar-expand-lg navbar-dark fixed-top" id="mainNav" style="background-color:#212529">
    <div class="container">
	  <a class="navbar-brand js-scroll-trigger" href="/#" style="font-family: monospace; color: white"><img height="52" src="assets/img/eidos_logo.png"/><img style="margin-left:20px" height="52" src="/assets/img/unito_logo.png"/>
      </a>
      <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
        Menu
        <i class="fas fa-bars"></i>
      </button>
      <div class="collapse navbar-collapse" id="navbarResponsive">
        <ul class="navbar-nav text-uppercase ml-auto"><li class="nav-item"><a class="nav-link js-scroll-trigger" href="/#services">Research</a></li>
		<li class="nav-item"><a class="nav-link js-scroll-trigger" href="/#portfolio">Projects</a></li>
		<li class="nav-item"><a class="nav-link js-scroll-trigger" href="/#timeline">About</a></li>
		<li class="nav-item"><a class="nav-link js-scroll-trigger" href="/#team">Team</a></li>
		<li class="nav-item"><a class="nav-link js-scroll-trigger" href="/#clients">Collaborations</a></li>
		<li class="nav-item"><a class="nav-link js-scroll-trigger" href="/#contact">Contact</a></li>
		<li class="nav-item"><a class="nav-link js-scroll-trigger" href="proposals">Thesis proposals</a></li>
		
          </li>
        </ul>
      </div>
    </div>
  </nav>
  <!-- End Navigation -->



<script>
document.getElementById("page-top").className="bg-light";
</script>


<div class="container" id="pagecontainer">
<h1 id="pruning-deep-neural-networks">Pruning deep neural networks</h1>

<p>Deep Neural Networks (DNNs) can solve challenging tasks thanks to complex stacks of (convolutional) layers with millions of learnable parameters. DNNs are however challenging to deploy in scenarios where memory is limited (e.g.,  mobile  devices),  since  their  memory  footprint  grows  linearly  with  the  number  of  parameters.  A  number  of strategies have been proposed to tackle this issue, including ad-hoc topology designs, parameter quantization and parameter  pruning.  Parameter pruning consists  in  dropping  synapses  between  neurons,  i.e.  setting  to  zero  part  of the  entries  in  the  matrices  representing  the  connections  between  layers.  Concerning  the  choice  of  the  parameters to prune, a number of different approaches have been proposed. Let us define the sensitivity of a parameter as the derivative of the network output(s) with respect to the parameter. It was shown that parameters with small sensitivity can be pruned from the topology with negligible impact  on  the  network  performance,  outperforming  approaches  based  on  norm  minimization.  Concerning  the network topology resulting from pruning, two different classes of strategies can be identified.</p>

<ul>
  <li>
    <p><strong>Unstructured</strong>  strategies aim  at  maximizing  the  pruning  ratio,  i.e.  the  number  of  parameters  pruned  from the  network,  regardless  of  the  resulting  topology.  For  example,  LOBSTER  (LOss  Based  SensitiviTyRegularization)  is  a  loss-based  regularizer  that  drives  some  but  not  all  parameters  towards  zero.  It  shrinks parameters for which the loss derivative is small, such that many parameters are first driven towards zero and then  pruned  with  a  threshold  mechanism.  In  a  number  of  scenarios,  this  method  yields  competitive  results in  terms  of  pruning  ratio.  The  resulting  connection  matrices  are  however  randomly  sparse,  i.e.  they  have  no structure. Representing sparse matrices in a memory efficient format is a non-trivial problem, thus high pruning ratios do not necessarily translate into reduced memory footprints.</p>
  </li>
  <li>
    <p><strong>Structured</strong>  strategies aim  at  pruning  parameters  from  the  network  yet  with  a  constraint  on  the  resulting topology.  For  example  SeReNe  (Sensitivity-based  Regularization  of  Neurons) is  a  method  for  learning sparse  topologies  with  a  structure,  exploiting  neural  sensitivity  as  a  regularizer.  Here,  the  sensitivity  of  a neuron  is  defined  as  the variation  of  the  network  output  with  respect  to  the  variation  of  the  activity  of  the neuron.  The  lower  the  sensitivity  of  a  neuron,  the  less  the  network  output  is  perturbed  if  the  neuron  output changes. This term is included in the cost function as a regularization term: in such way, SeReNe is able to prune entire neurons at the cost of a somewhat lower pruning ratio.</p>
  </li>
</ul>

<div class="row">
<iframe width="560" height="315" src="https://www.youtube.com/embed/jp_g0LrXBgc" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" style="margin: auto"></iframe>
</div>

<p><strong>References:</strong></p>

<p>[1] Tartaglione, E., Lepsøy, S., Fiandrotti, A., &amp; Francini, G. (2018). Learning Sparse Neural Networks via Sensitivity-Driven Regularization. NeurIPS.</p>

<p>[2] Tartaglione, Enzo, Andrea Bragagnolo, and Marco Grangetto. “Pruning artificial neural networks: a way to find well-generalizing, high-entropy sharp minima.” International Conference on Artificial Neural Networks. Springer, Cham, 2020.</p>

<p>[3] Tartaglione, E., Bragagnolo, A., Odierna, F., Fiandrotti, A., &amp; Grangetto, M. (2021). SeReNe: Sensitivity based Regularization of Neurons for Structured Sparsity in Neural Networks. arXiv preprint arXiv:2102.03773.</p>

<p>[4] Tartaglione, E., Bragagnolo, A., Fiandrotti, A., &amp; Grangetto, M. (2020). LOss-Based SensiTivity rEgulaRization: towards deep sparse neural networks. arXiv preprint arXiv:2011.09905.</p>

</div>


	    <!-- Footer -->
  <footer class="footer" id="footer" style="background-color:white;">
    <div class="container">
      <div class="row align-items-center">
        <div class="col-md-4">
          <span class="copyright">Copyright &copy; EIDOSlab 2021</span>
        </div>
		<!-- Social Media -->
        <div class="col-md-4">
          <ul class="list-inline social-buttons">
		  
            <li class="list-inline-item">
			  
              <a href="https://github.com/eidoslab">
                <i class="fab fa-github"></i>
              </a>
			  
            </li>
			
          </ul>
        </div>
		<!-- Legal -->
        <div class="col-md-4">
          <ul class="list-inline quicklinks">
            <li class="list-inline-item">
              <a href="legal">Privacy Policy</a>
            </li>
          </ul>
        </div>
      </div>
    </div>
  </footer>

<script>
fixPageShort();
function fixPageShort() {
  if(window.innerHeight > document.body.offsetHeight) {
    document.getElementById("footer").style.position="fixed";
    document.getElementById("footer").style.bottom=0;
    document.getElementById("footer").style.right=0;
    document.getElementById("footer").style.left=0;
    document.getElementById("footer").style.width="100%";
  }
}
</script>

  <!-- End Footer -->

	  <!-- Bootstrap core JavaScript -->
	  <script src="assets/js/jquery.min.js"></script>
	  <script src="assets/js/bootstrap.bundle.min.js"></script>

	  <!-- Plugin JavaScript -->
	  <script src="assets/js/jquery.easing.min.js"></script>

	  <!-- Contact form JavaScript -->
	  <script src="assets/js/jqBootstrapValidation.js"></script>
	  <script src="assets/js/contact_me.js"></script>

	  <!-- Custom scripts for this template -->
	  <script src="assets/js/agency.min.js"></script>

  </body>
</html>
